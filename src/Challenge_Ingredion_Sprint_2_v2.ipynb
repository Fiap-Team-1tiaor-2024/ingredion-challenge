{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goJQLbQYgcVE"
      },
      "source": [
        "\n",
        "\n",
        "# Challenge Ingredion - Sprint 2\n",
        "Este notebook foi desenvolvido para o Challenge em parceria com a Ingredion, na Sprint 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_zLnZPiHDF5"
      },
      "source": [
        "### Aplicação da Técnica de Segmentação - SAM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYgO5jkCS47l"
      },
      "source": [
        "**Célula** 0: Montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAOf7pooSlBF"
      },
      "outputs": [],
      "source": [
        "# Montar Google Drive (Necessário no Colab para acessar/salvar arquivos no Drive)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Google Drive montado com sucesso.\")\n",
        "    # Verificar se os diretórios de dados existem (opcional, mas útil)\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Não está no ambiente Google Colab ou erro ao montar Drive.\")\n",
        "    # Se não estiver no Colab, ajuste os caminhos para serem locais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nobJ5-Z6rBc"
      },
      "source": [
        "**Célula** 1: Instalação, Imports e Configurações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6XwTj74ld8p",
        "outputId": "2978fe9d-cb98-4a37-85da-447a7fe4219b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caminho PROD_CSV_PATH: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/Producao.csv\n",
            "Caminho NDVI_CSV_PATH: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/NDVI.csv\n",
            "Usando dispositivo: cpu\n"
          ]
        }
      ],
      "source": [
        "#!pip install torch torchvision albumentations opencv-python-headless matplotlib numpy pandas seaborn scikit-learn\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2 # Importante se usar ToTensorV2() nas transforms\n",
        "from sklearn.model_selection import train_test_split # Para divisão treino/teste\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# --- Configurações e Caminhos ---\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data\"\n",
        "\n",
        "if not os.path.isdir(DRIVE_BASE_PATH):\n",
        "  print(f\"Aviso: Diretório base '{DRIVE_BASE_PATH}' não encontrado no Drive. Verifique os caminhos.\")\n",
        "\n",
        "IMAGE_TRAIN_DIR = os.path.join(DRIVE_BASE_PATH, \"train/images\")\n",
        "MASK_TRAIN_DIR = os.path.join(DRIVE_BASE_PATH, \"train/masks\")\n",
        "IMAGE_VAL_DIR = os.path.join(DRIVE_BASE_PATH, \"val/images\")\n",
        "MASK_VAL_DIR = os.path.join(DRIVE_BASE_PATH, \"val/masks\")\n",
        "IMAGE_TEST_DIR = os.path.join(DRIVE_BASE_PATH, \"test/images\")\n",
        "MASK_TEST_DIR = os.path.join(DRIVE_BASE_PATH, \"test/masks\")\n",
        "\n",
        "PROD_CSV_PATH = os.path.join(DRIVE_BASE_PATH, \"Producao.csv\")\n",
        "print(f\"Caminho PROD_CSV_PATH: {PROD_CSV_PATH}\")\n",
        "NDVI_CSV_PATH = os.path.join(DRIVE_BASE_PATH, \"NDVI.csv\")\n",
        "print(f\"Caminho NDVI_CSV_PATH: {NDVI_CSV_PATH}\")\n",
        "\n",
        "# Caminho para salvar o melhor modelo de segmentação\n",
        "# Salvar no Drive é recomendado para persistência entre sessões do Colab\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True) # Cria o diretório se não existir\n",
        "BEST_MODEL_PATH = os.path.join(SAVE_DIR, 'best_segmentation_model.pth')\n",
        "\n",
        "# Parâmetros de Treinamento (Segmentação)\n",
        "NUM_EPOCHS_SEGMENTATION = 10 # AJUSTE (10 é baixo para resultados reais)\n",
        "BATCH_SIZE_SEGMENTATION = 4\n",
        "LEARNING_RATE_SEGMENTATION = 1e-4\n",
        "\n",
        "# Parâmetros de Modelagem (Previsão de Rendimento)\n",
        "RANDOM_STATE = 42\n",
        "N_ESTIMATORS_RF = 100\n",
        "TEST_YEARS_SPLIT = 10 # Número de anos recentes para usar como teste\n",
        "\n",
        "# Configuração do dispositivo (GPU ou CPU)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Usando dispositivo: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UOWDVos0Q-i",
        "outputId": "89636eb8-9fd5-4564-f8e0-4c9503314c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Iniciando Geração Dinâmica de Máscaras (Método de Otsu com Verificação) ---\n",
            "\n",
            "Processando diretório: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/train/images\n",
            "Encontradas 4 imagens .jpg.\n",
            "Diretório /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/train/images concluído.\n",
            "\n",
            "Processando diretório: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/val/images\n",
            "Encontradas 3 imagens .jpg.\n",
            "Diretório /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/val/images concluído.\n",
            "\n",
            "Processando diretório: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/test/images\n",
            "Encontradas 3 imagens .jpg.\n",
            "Diretório /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/test/images concluído.\n",
            "\n",
            "--- Processamento Concluído ---\n",
            "Total de NOVAS máscaras geradas: 10\n",
            "Total de imagens PULADAS (máscara já existia): 0\n",
            "Total de erros encontrados durante o processamento: 0\n",
            "Tempo total: 0.60 segundos\n",
            "Máscaras salvas (ou verificadas) nos diretórios: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/train/masks, /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/val/masks, /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/data/test/masks\n"
          ]
        }
      ],
      "source": [
        "# Célula para Geração Dinâmica de Máscaras (Otsu com Verificação de Existência)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- Diretórios (Definidos na Célula 1) ---\n",
        "# Certifique-se que estas variáveis da Célula 1 estão definidas corretamente:\n",
        "# DRIVE_BASE_PATH, IMAGE_TRAIN_DIR, MASK_TRAIN_DIR, IMAGE_VAL_DIR, MASK_VAL_DIR, IMAGE_TEST_DIR, MASK_TEST_DIR\n",
        "\n",
        "print(\"--- Iniciando Geração Dinâmica de Máscaras (Método de Otsu com Verificação) ---\")\n",
        "\n",
        "# Lista de pares de diretórios (entrada de imagens, saída de máscaras)\n",
        "dir_pairs = [\n",
        "    (IMAGE_TRAIN_DIR, MASK_TRAIN_DIR),\n",
        "    (IMAGE_VAL_DIR, MASK_VAL_DIR),\n",
        "    (IMAGE_TEST_DIR, MASK_TEST_DIR)\n",
        "]\n",
        "\n",
        "total_images_processed = 0\n",
        "total_errors = 0\n",
        "total_skipped = 0 # Contador para imagens puladas\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop pelos pares de diretórios (train, val, test)\n",
        "for img_dir, mask_dir in dir_pairs:\n",
        "    print(f\"\\nProcessando diretório: {img_dir}\")\n",
        "\n",
        "    if not os.path.isdir(img_dir):\n",
        "        print(f\"Aviso: Diretório de entrada não encontrado: {img_dir}. Pulando.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        os.makedirs(mask_dir, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Erro ao criar diretório de saída {mask_dir}: {e}. Pulando este diretório.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        image_files = [f for f in os.listdir(img_dir) if f.lower().endswith('.jpg')]\n",
        "        print(f\"Encontradas {len(image_files)} imagens .jpg.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao listar arquivos em {img_dir}: {e}. Pulando este diretório.\")\n",
        "        continue\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"Nenhuma imagem .jpg encontrada para processar.\")\n",
        "        continue\n",
        "\n",
        "    # Loop por cada imagem no diretório atual\n",
        "    for img_filename in image_files:\n",
        "        image_path = os.path.join(img_dir, img_filename)\n",
        "\n",
        "        # --- INÍCIO DA VERIFICAÇÃO ---\n",
        "        # Construir o nome e caminho esperado para a máscara de saída\n",
        "        mask_filename = os.path.splitext(img_filename)[0] + \"_mask.png\"\n",
        "        save_path = os.path.join(mask_dir, mask_filename)\n",
        "\n",
        "        # Verificar se a máscara já existe\n",
        "        if os.path.exists(save_path):\n",
        "            # print(f\"  Máscara já existe para {img_filename}. Pulando.\") # Descomente se quiser log detalhado\n",
        "            total_skipped += 1\n",
        "            continue # Pula para a próxima imagem no loop interno\n",
        "        # --- FIM DA VERIFICAÇÃO ---\n",
        "\n",
        "        # Se a máscara não existe, processa a imagem\n",
        "        try:\n",
        "            img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img_gray is None:\n",
        "                if not os.path.exists(image_path):\n",
        "                   print(f\"Erro: Arquivo não encontrado {image_path}. Pulando.\")\n",
        "                else:\n",
        "                   print(f\"Erro: Imagem não pode ser lida ou está vazia: {img_filename}. Pulando.\")\n",
        "                total_errors += 1\n",
        "                continue\n",
        "\n",
        "            # Aplicar Binarização de Otsu\n",
        "            ret_otsu, mask_otsu = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "            # Salvar a máscara gerada\n",
        "            success = cv2.imwrite(save_path, mask_otsu)\n",
        "            if not success:\n",
        "                print(f\"Erro ao salvar máscara para {img_filename} em {save_path}. Pulando.\")\n",
        "                total_errors += 1\n",
        "                continue\n",
        "\n",
        "            total_images_processed += 1\n",
        "            if total_images_processed % 50 == 0:\n",
        "                print(f\"  {total_images_processed} novas máscaras geradas...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar imagem {img_filename}: {e}. Pulando.\")\n",
        "            total_errors += 1\n",
        "\n",
        "    print(f\"Diretório {img_dir} concluído.\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"\\n--- Processamento Concluído ---\")\n",
        "print(f\"Total de NOVAS máscaras geradas: {total_images_processed}\")\n",
        "print(f\"Total de imagens PULADAS (máscara já existia): {total_skipped}\")\n",
        "print(f\"Total de erros encontrados durante o processamento: {total_errors}\")\n",
        "print(f\"Tempo total: {elapsed_time:.2f} segundos\")\n",
        "print(f\"Máscaras salvas (ou verificadas) nos diretórios: {MASK_TRAIN_DIR}, {MASK_VAL_DIR}, {MASK_TEST_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSV1WTx6vAG"
      },
      "source": [
        "Célula 2: Definição da Classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx0gBlqkld8p",
        "outputId": "02295dde-1580-4722-bc7d-69acef3bd0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classe SatelliteDataset definida.\n"
          ]
        }
      ],
      "source": [
        "# Classe Dataset para carregar imagens e máscaras de segmentação\n",
        "class SatelliteDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        # Filtrar para garantir que estamos lendo apenas arquivos de imagem esperados (ex: .jpg)\n",
        "        try:\n",
        "          self.images = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]\n",
        "        except FileNotFoundError:\n",
        "          print(f\"Erro: Diretório de imagens não encontrado: {image_dir}\")\n",
        "          self.images = []\n",
        "          # Levantar erro ou tratar como apropriado\n",
        "          # raise\n",
        "\n",
        "        # Verifique se todos os arquivos têm máscaras correspondentes\n",
        "        missing_masks = []\n",
        "        valid_images = []\n",
        "        if self.images: # Procede apenas se encontrou imagens\n",
        "            for img_name in self.images:\n",
        "                mask_name = img_name.replace(\".jpg\", \"_mask.png\") # Assumindo convenção _mask.png\n",
        "                mask_path = os.path.join(mask_dir, mask_name)\n",
        "                if os.path.exists(mask_path):\n",
        "                    valid_images.append(img_name)\n",
        "                else:\n",
        "                    missing_masks.append(mask_path)\n",
        "\n",
        "            if missing_masks:\n",
        "                print(f\"Aviso: Máscaras não encontradas para {len(missing_masks)} imagens em {mask_dir}.\")\n",
        "                # print(f\"Exemplos de máscaras faltando: {missing_masks[:5]}\") # Descomente para debug\n",
        "            self.images = valid_images # Use only images with corresponding masks\n",
        "        else:\n",
        "            print(f\"Nenhuma imagem .jpg encontrada em {image_dir}\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not self.images: return None, None # Lida com caso de diretório vazio\n",
        "\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_name = img_name.replace(\".jpg\", \"_mask.png\")\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                # Tentar carregar mesmo se nome tiver case diferente (comum em alguns sistemas)\n",
        "                if not os.path.exists(img_path):\n",
        "                   raise FileNotFoundError(f\"Arquivo de imagem não encontrado: {img_path}\")\n",
        "                raise ValueError(f\"Imagem não pode ser lida ou está vazia: {img_path}\")\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if mask is None:\n",
        "                 # Tentar carregar mesmo se nome tiver case diferente\n",
        "                 if not os.path.exists(mask_path):\n",
        "                    raise FileNotFoundError(f\"Arquivo de máscara não encontrado: {mask_path}\")\n",
        "                 raise ValueError(f\"Máscara não pode ser lida ou está vazia: {mask_path}\")\n",
        "\n",
        "            # Normalizar máscara para 0 ou 1 (assumindo valores originais 0 e 255)\n",
        "            mask = (mask > 128).astype(np.float32) # Convert to 0.0 or 1.0\n",
        "\n",
        "            # Aplicar transformações\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=image, mask=mask)\n",
        "                image = augmented['image']\n",
        "                mask = augmented['mask']\n",
        "\n",
        "            # Converter para Tensor PyTorch CHW (se a transform não o fez)\n",
        "            # A.Normalize geralmente retorna numpy HWC; A.ToTensorV2 retorna tensor CHW\n",
        "            if isinstance(image, np.ndarray):\n",
        "                 # Normalização geralmente resulta em float32 HWC\n",
        "                 image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "            if isinstance(mask, np.ndarray):\n",
        "                 # Máscara é HW, converter para tensor float\n",
        "                 mask = torch.from_numpy(mask).float()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar item {idx} ({img_name}): {e}\")\n",
        "            return None, None # Retorna None para ser tratado pelo collate_fn\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "print(\"Classe SatelliteDataset definida.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYoi9Ujg62bL"
      },
      "source": [
        "Célula 3: Transformações e DataLoaders (Segmentação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynjnWFqld8p",
        "outputId": "d11b7a86-073a-40ba-c8bc-108c06fca538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataLoader criado com 4 imagens.\n",
            "Validation DataLoader criado com 3 imagens.\n",
            "Test DataLoader criado com 3 imagens.\n",
            "\n",
            "Transformações e DataLoaders definidos.\n"
          ]
        }
      ],
      "source": [
        "# Transformações (usando médias/std da ImageNet)\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    # Se não usar ToTensorV2, a conversão para Tensor e permuta é feita no __getitem__\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Criar Datasets e DataLoaders\n",
        "try:\n",
        "    train_dataset = SatelliteDataset(IMAGE_TRAIN_DIR, MASK_TRAIN_DIR, train_transform)\n",
        "    val_dataset = SatelliteDataset(IMAGE_VAL_DIR, MASK_VAL_DIR, val_transform)\n",
        "    test_dataset = SatelliteDataset(IMAGE_TEST_DIR, MASK_TEST_DIR, val_transform)\n",
        "\n",
        "    # Função collate para lidar com possíveis Nones retornados por __getitem__\n",
        "    def collate_fn(batch):\n",
        "        batch = list(filter(lambda x: x is not None and x[0] is not None, batch))\n",
        "        if not batch: return None # Retorna None se o batch inteiro falhar\n",
        "        return torch.utils.data.dataloader.default_collate(batch)\n",
        "\n",
        "    # Verificar se os datasets foram criados com sucesso antes de criar DataLoaders\n",
        "    if len(train_dataset) > 0:\n",
        "       train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_SEGMENTATION, shuffle=True, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n",
        "       print(f\"Train DataLoader criado com {len(train_dataset)} imagens.\")\n",
        "    else:\n",
        "       train_loader = None\n",
        "       print(f\"Aviso: Train dataset vazio ou não pôde ser carregado de {IMAGE_TRAIN_DIR}. DataLoader de treino não criado.\")\n",
        "\n",
        "    if len(val_dataset) > 0:\n",
        "       val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_SEGMENTATION, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n",
        "       print(f\"Validation DataLoader criado com {len(val_dataset)} imagens.\")\n",
        "    else:\n",
        "       val_loader = None\n",
        "       print(f\"Aviso: Validation dataset vazio ou não pôde ser carregado de {IMAGE_VAL_DIR}. DataLoader de validação não criado.\")\n",
        "\n",
        "    if len(test_dataset) > 0:\n",
        "      test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn, pin_memory=True) # Batch size 1 para teste/inferência\n",
        "      print(f\"Test DataLoader criado com {len(test_dataset)} imagens.\")\n",
        "    else:\n",
        "      test_loader = None\n",
        "      print(f\"Aviso: Test dataset vazio ou não pôde ser carregado de {IMAGE_TEST_DIR}. DataLoader de teste não criado.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao criar Datasets/DataLoaders de segmentação: {e}\")\n",
        "    # Considerar parar a execução se os loaders não puderem ser criados\n",
        "    # raise e\n",
        "\n",
        "print(\"\\nTransformações e DataLoaders definidos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxqbt4r665Bu"
      },
      "source": [
        "Célula 4: Definição do Modelo de Segmentação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpwKiz3Bld8p",
        "outputId": "7a621b1b-96a8-4bf6-f323-bd89f4988d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo de segmentação DeepLabV3+ definido com pesos atualizados e movido para o dispositivo.\n",
            "Caminho para salvar melhor modelo: /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth\n"
          ]
        }
      ],
      "source": [
        "# 1. Obtenha os pesos pré-treinados recomendados (DEFAULT)\n",
        "weights = DeepLabV3_ResNet50_Weights.DEFAULT\n",
        "\n",
        "# 2. Carregue o modelo DeepLabV3 pré-treinado usando o parâmetro 'weights'\n",
        "model_segmentation = deeplabv3_resnet50(weights=weights)\n",
        "\n",
        "# ----- Fim da Correção -----\n",
        "\n",
        "# Modificar a última camada para 1 classe de saída (segmentação binária)\n",
        "# A estrutura para acessar a camada final (classifier[4]) geralmente é estável,\n",
        "# mas se encontrar erro aqui após atualizar, verifique a estrutura do modelo (print(model_segmentation))\n",
        "model_segmentation.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
        "\n",
        "# Mover o modelo para o dispositivo (GPU ou CPU)\n",
        "# Certifique-se que DEVICE está definido em alguma célula anterior\n",
        "model_segmentation = model_segmentation.to(DEVICE)\n",
        "\n",
        "# Definir Loss e Optimizer\n",
        "criterion_segmentation = nn.BCEWithLogitsLoss() # Correto para saída binária com logits\n",
        "# Certifique-se que LEARNING_RATE_SEGMENTATION está definido em alguma célula anterior\n",
        "optimizer_segmentation = optim.Adam(model_segmentation.parameters(), lr=LEARNING_RATE_SEGMENTATION)\n",
        "\n",
        "# Certifique-se que BEST_MODEL_PATH está definido em alguma célula anterior\n",
        "print(\"Modelo de segmentação DeepLabV3+ definido com pesos atualizados e movido para o dispositivo.\")\n",
        "print(f\"Caminho para salvar melhor modelo: {BEST_MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51w7cEdL7Fm6"
      },
      "source": [
        "Célula 5: Função de Cálculo IoU (Segmentação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjX0_YVBld8q",
        "outputId": "a8569c41-3250-4f07-82a9-2003a9d1f5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Função calculate_iou definida.\n"
          ]
        }
      ],
      "source": [
        "# Função para calcular Intersection over Union (IoU)\n",
        "def calculate_iou(pred, target, threshold=0.5):\n",
        "    \"\"\"Calcula IoU para segmentação binária usando tensores PyTorch.\"\"\"\n",
        "    # Garantir que os tensores estão na CPU e são do tipo float para operações\n",
        "    pred = pred.detach().cpu().float()\n",
        "    target = target.detach().cpu().float()\n",
        "\n",
        "    pred_bool = (pred > threshold)\n",
        "    target_bool = (target > 0.5) # Mascaras já devem ser 0 ou 1\n",
        "\n",
        "    intersection = torch.logical_and(pred_bool, target_bool).sum().float()\n",
        "    union = torch.logical_or(pred_bool, target_bool).sum().float()\n",
        "\n",
        "    # Adicionar epsilon para evitar divisão por zero se a união for 0\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    return iou.item()\n",
        "\n",
        "print(\"Função calculate_iou definida.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxMyh23o7Lcw"
      },
      "source": [
        "Célula 6: Treinamento do Modelo de Segmentação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbrZDLBZld8q",
        "outputId": "3cdd4db2-6a9a-4635-fa29-0c77bf339aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Iniciando Treinamento (10 épocas) ---\n",
            "Epoch 1/10 | Train Loss: 0.6909 | Train IoU: 0.0003 | Val Loss: 0.6573 | Val IoU: 0.1470\n",
            "---> Modelo salvo em /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth (Melhor Val IoU: 0.1470)\n",
            "Epoch 2/10 | Train Loss: 0.6296 | Train IoU: 0.1084 | Val Loss: 0.6723 | Val IoU: 0.2544\n",
            "---> Modelo salvo em /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth (Melhor Val IoU: 0.2544)\n",
            "Epoch 3/10 | Train Loss: 0.6361 | Train IoU: 0.0859 | Val Loss: 0.6675 | Val IoU: 0.3178\n",
            "---> Modelo salvo em /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth (Melhor Val IoU: 0.3178)\n",
            "Epoch 4/10 | Train Loss: 0.5917 | Train IoU: 0.3167 | Val Loss: 0.6628 | Val IoU: 0.3327\n",
            "---> Modelo salvo em /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth (Melhor Val IoU: 0.3327)\n",
            "Epoch 5/10 | Train Loss: 0.5870 | Train IoU: 0.3477 | Val Loss: 0.6513 | Val IoU: 0.3353\n",
            "---> Modelo salvo em /content/drive/MyDrive/Colab Notebooks/FIAP/Fase 6/Atividade - Challenge/output/best_segmentation_model.pth (Melhor Val IoU: 0.3353)\n",
            "Epoch 6/10 | Train Loss: 0.5766 | Train IoU: 0.3985 | Val Loss: 0.6436 | Val IoU: 0.3318\n"
          ]
        }
      ],
      "source": [
        "# Verificar se o train_loader e val_loader foram criados\n",
        "if train_loader and val_loader:\n",
        "    print(f\"\\n--- Iniciando Treinamento ({NUM_EPOCHS_SEGMENTATION} épocas) ---\")\n",
        "    best_val_iou = -1.0 # Iniciar com valor baixo\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS_SEGMENTATION):\n",
        "        model_segmentation.train()\n",
        "        train_loss = 0.0\n",
        "        train_iou = 0.0\n",
        "        processed_batches_train = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            if batch is None: continue # Pular batch inválido\n",
        "\n",
        "            images, masks = batch\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "            # Garantir que a máscara tenha o shape correto [B, H, W]\n",
        "            if masks.dim() == 4 and masks.shape[1] == 1:\n",
        "                 masks = masks.squeeze(1)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model_segmentation(images)['out'] # Shape [B, 1, H, W]\n",
        "            loss = criterion_segmentation(outputs.squeeze(1), masks) # Squeeze output para [B, H, W]\n",
        "\n",
        "            # Backward pass e otimização\n",
        "            optimizer_segmentation.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_segmentation.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            preds = torch.sigmoid(outputs.squeeze(1))\n",
        "            train_iou += calculate_iou(preds, masks) # Passar tensores diretamente\n",
        "            processed_batches_train += 1\n",
        "\n",
        "        avg_train_loss = train_loss / processed_batches_train if processed_batches_train > 0 else 0\n",
        "        avg_train_iou = train_iou / processed_batches_train if processed_batches_train > 0 else 0\n",
        "\n",
        "        # Validação\n",
        "        model_segmentation.eval()\n",
        "        val_loss = 0.0\n",
        "        val_iou = 0.0\n",
        "        processed_batches_val = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                if batch is None: continue\n",
        "                images, masks = batch\n",
        "                images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "                if masks.dim() == 4 and masks.shape[1] == 1:\n",
        "                     masks = masks.squeeze(1)\n",
        "\n",
        "                outputs = model_segmentation(images)['out']\n",
        "                loss = criterion_segmentation(outputs.squeeze(1), masks)\n",
        "                val_loss += loss.item()\n",
        "                preds = torch.sigmoid(outputs.squeeze(1))\n",
        "                val_iou += calculate_iou(preds, masks)\n",
        "                processed_batches_val += 1\n",
        "\n",
        "        avg_val_loss = val_loss / processed_batches_val if processed_batches_val > 0 else 0\n",
        "        avg_val_iou = val_iou / processed_batches_val if processed_batches_val > 0 else 0\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{NUM_EPOCHS_SEGMENTATION} | '\n",
        "              f'Train Loss: {avg_train_loss:.4f} | Train IoU: {avg_train_iou:.4f} | '\n",
        "              f'Val Loss: {avg_val_loss:.4f} | Val IoU: {avg_val_iou:.4f}')\n",
        "\n",
        "        # Salvar o melhor modelo\n",
        "        if avg_val_iou > best_val_iou:\n",
        "            best_val_iou = avg_val_iou\n",
        "            try:\n",
        "                torch.save(model_segmentation.state_dict(), BEST_MODEL_PATH)\n",
        "                print(f'---> Modelo salvo em {BEST_MODEL_PATH} (Melhor Val IoU: {best_val_iou:.4f})')\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao salvar o modelo em {BEST_MODEL_PATH}: {e}\")\n",
        "\n",
        "    print(\"\\n--- Treinamento de segmentação concluído. ---\")\n",
        "else:\n",
        "    print(\"\\n--- Treinamento de segmentação pulado pois DataLoaders não foram criados corretamente. ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz_575yY7PNS"
      },
      "source": [
        "Célula 7: Avaliação do Modelo de Segmentação (Test Set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XACdSvc7R1z"
      },
      "outputs": [],
      "source": [
        "# Verificar se o test_loader existe e se o modelo foi salvo\n",
        "if test_loader and os.path.exists(BEST_MODEL_PATH):\n",
        "    print(\"\\n--- Avaliando Melhor Modelo de Segmentação no Conjunto de Teste ---\")\n",
        "    try:\n",
        "        # Carregar o melhor modelo salvo\n",
        "        model_segmentation.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE)) # Usar map_location\n",
        "        model_segmentation.eval()\n",
        "\n",
        "        test_loss = 0.0\n",
        "        test_iou = 0.0\n",
        "        processed_batches_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                if batch is None: continue\n",
        "                images, masks = batch\n",
        "                images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "                if masks.dim() == 4 and masks.shape[1] == 1:\n",
        "                    masks = masks.squeeze(1)\n",
        "\n",
        "                outputs = model_segmentation(images)['out']\n",
        "                # Tratamento para caso raro de output não ter a dimensão esperada\n",
        "                if outputs.dim() == 4 and outputs.shape[1] == 1:\n",
        "                   outputs_squeezed = outputs.squeeze(1)\n",
        "                else:\n",
        "                   # Lidar com caso inesperado, talvez pular o batch\n",
        "                   print(f\"Aviso: Shape de output inesperado: {outputs.shape}\")\n",
        "                   continue\n",
        "\n",
        "                loss = criterion_segmentation(outputs_squeezed, masks)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                preds = torch.sigmoid(outputs_squeezed)\n",
        "                test_iou += calculate_iou(preds, masks)\n",
        "                processed_batches_test += 1\n",
        "\n",
        "        if processed_batches_test > 0:\n",
        "          avg_test_loss = test_loss / processed_batches_test\n",
        "          avg_test_iou = test_iou / processed_batches_test\n",
        "          print(f'Resultados no Teste: Loss: {avg_test_loss:.4f} | IoU: {avg_test_iou:.4f}')\n",
        "        else:\n",
        "            print(\"Nenhum batch de teste pôde ser processado.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Melhor modelo de segmentação não encontrado em {BEST_MODEL_PATH}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro durante a avaliação no teste de segmentação: {e}\")\n",
        "else:\n",
        "    if not test_loader: print(\"\\n--- Avaliação de teste pulada: Test DataLoader não disponível.\")\n",
        "    if not os.path.exists(BEST_MODEL_PATH): print(f\"\\n--- Avaliação de teste pulada: Modelo {BEST_MODEL_PATH} não encontrado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dpto5tx7V1S"
      },
      "source": [
        "Célula 8: Função de Predição e Visualização (Segmentação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc-WGz0l7ZV6"
      },
      "outputs": [],
      "source": [
        "# Função para prever máscara de uma imagem individual\n",
        "def predict_single_image(image_path, model, device, transform):\n",
        "    \"\"\"Prevê a máscara de segmentação para um único arquivo de imagem.\"\"\"\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Aviso: Arquivo não encontrado: {image_path}\")\n",
        "        return None, None # Retorna None se o arquivo não existe\n",
        "\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Falha ao ler a imagem: {image_path}\")\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Aplicar transformações de validação/teste\n",
        "        augmented = transform(image=image_rgb)\n",
        "        input_image_transformed = augmented['image']\n",
        "\n",
        "        # Converter para tensor CHW\n",
        "        if isinstance(input_image_transformed, np.ndarray):\n",
        "            input_tensor = torch.from_numpy(input_image_transformed).permute(2, 0, 1).float()\n",
        "        elif isinstance(input_image_transformed, torch.Tensor):\n",
        "            input_tensor = input_image_transformed.float()\n",
        "            if input_tensor.dim() == 3 and input_tensor.shape[2] == 3:\n",
        "                 input_tensor = input_tensor.permute(2, 0, 1)\n",
        "        else:\n",
        "             raise TypeError(\"Tipo de saída inesperado da transformação.\")\n",
        "\n",
        "        input_tensor = input_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Predição\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)['out'].squeeze(0) # Remove B dim -> [C, H, W]\n",
        "\n",
        "        # Processa a saída para máscara binária NumPy\n",
        "        # Remove C dim (era 1), aplica sigmoid, threshold, move para CPU, numpy\n",
        "        pred_mask = (torch.sigmoid(output.squeeze(0)) > 0.5).cpu().numpy()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao prever imagem {image_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    return pred_mask, image_rgb\n",
        "\n",
        "# Visualizar um exemplo do conjunto de teste (se disponível)\n",
        "if test_dataset and len(test_dataset) > 0 and os.path.exists(BEST_MODEL_PATH):\n",
        "    print(\"\\n--- Visualizando Exemplo de Predição de Segmentação ---\")\n",
        "    try:\n",
        "        # Carregar modelo (caso não esteja carregado)\n",
        "        if 'model_segmentation' not in locals() or model_segmentation is None:\n",
        "             model_segmentation = deeplabv3_resnet50(pretrained=False) # Não precisa pré-treinado aqui\n",
        "             model_segmentation.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
        "             model_segmentation.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
        "             model_segmentation = model_segmentation.to(DEVICE)\n",
        "             model_segmentation.eval()\n",
        "\n",
        "        # Obter item de teste\n",
        "        item_idx = 0 # Pega o primeiro item\n",
        "        test_image_name = test_dataset.images[item_idx]\n",
        "        test_image_path = os.path.join(IMAGE_TEST_DIR, test_image_name)\n",
        "\n",
        "        # Obter máscara real do dataset (já processada)\n",
        "        _, mask_real_tensor = test_dataset[item_idx]\n",
        "        if mask_real_tensor is not None:\n",
        "           mask_real_np = mask_real_tensor.cpu().numpy() # Converte para numpy\n",
        "\n",
        "           # Fazer a predição\n",
        "           pred_mask_np, original_image_np = predict_single_image(\n",
        "               test_image_path, model_segmentation, DEVICE, val_transform\n",
        "           )\n",
        "\n",
        "           if pred_mask_np is not None:\n",
        "              # Calcular IoU para este exemplo\n",
        "              iou_example = calculate_iou(torch.tensor(pred_mask_np), torch.tensor(mask_real_np))\n",
        "\n",
        "              # Plot\n",
        "              plt.figure(figsize=(15, 5))\n",
        "              plt.subplot(1, 3, 1)\n",
        "              plt.imshow(original_image_np)\n",
        "              plt.title(f'Original ({test_image_name})')\n",
        "              plt.axis('off')\n",
        "\n",
        "              plt.subplot(1, 3, 2)\n",
        "              plt.imshow(mask_real_np, cmap='gray')\n",
        "              plt.title('Máscara Real')\n",
        "              plt.axis('off')\n",
        "\n",
        "              plt.subplot(1, 3, 3)\n",
        "              plt.imshow(pred_mask_np, cmap='gray')\n",
        "              plt.title(f'Predição (IoU: {iou_example:.2f})')\n",
        "              plt.axis('off')\n",
        "              plt.tight_layout()\n",
        "              plt.show()\n",
        "           else:\n",
        "              print(f\"Falha ao gerar predição para {test_image_path}\")\n",
        "        else:\n",
        "            print(f\"Falha ao obter máscara real para o item de teste {item_idx}\")\n",
        "\n",
        "    except IndexError:\n",
        "        print(\"Índice fora do alcance no dataset de teste.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao visualizar exemplo de segmentação: {e}\")\n",
        "else:\n",
        "     print(\"\\n--- Visualização de segmentação pulada (Dataset de teste ou modelo não disponível). ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYQ4SOLA7qht"
      },
      "source": [
        "Célula 9: Carregar e Pré-processar Dados Tabulares (Produtividade e NDVI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo-VcGIA7sL9"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Carregando e Processando Dados Tabulares ---\")\n",
        "\n",
        "# --- Carregar Produtividade ---\n",
        "df_prod = None # Inicializa para verificar carregamento\n",
        "try:\n",
        "    df_prod = pd.read_csv(PROD_CSV_PATH)\n",
        "    print(f\"Arquivo de produtividade '{PROD_CSV_PATH}' carregado.\")\n",
        "    # Selecionar e renomear colunas\n",
        "    cols_prod_to_keep = {\n",
        "        'Ano': 'Ano',\n",
        "        'Área colhida (Hectares)': 'Area_Colhida_ha',\n",
        "        'Rendimento médio da produção (Quilogramas por Hectare)': 'Rendimento_Medio_kg_ha'\n",
        "    }\n",
        "    # Verifica se todas as colunas ORIGINAIS existem\n",
        "    if all(col in df_prod.columns for col in cols_prod_to_keep.keys()):\n",
        "        df_prod = df_prod[list(cols_prod_to_keep.keys())].copy()\n",
        "        df_prod.rename(columns=cols_prod_to_keep, inplace=True)\n",
        "        df_prod['Ano'] = df_prod['Ano'].astype(int)\n",
        "        print(\"Dados de produtividade selecionados e limpos.\")\n",
        "        print(\"Head df_prod:\")\n",
        "        print(df_prod.head())\n",
        "    else:\n",
        "        print(f\"Aviso: Colunas esperadas ({list(cols_prod_to_keep.keys())}) não encontradas em {PROD_CSV_PATH}\")\n",
        "        print(f\"Colunas encontradas: {df_prod.columns.tolist()}\")\n",
        "        df_prod = None # Anula se não encontrar colunas\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro Crítico: Arquivo de produtividade '{PROD_CSV_PATH}' não encontrado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro Crítico ao processar produtividade: {e}\")\n",
        "\n",
        "# --- Carregar e Limpar NDVI ---\n",
        "df_ndvi = None # Inicializa\n",
        "if df_prod is not None: # Só tenta carregar NDVI se produtividade carregou\n",
        "    try:\n",
        "        df_ndvi = pd.read_csv(NDVI_CSV_PATH, header=2) # Usa header=2 conforme descoberto\n",
        "        if len(df_ndvi.columns) >= 2:\n",
        "            # Renomeia as duas primeiras colunas e seleciona\n",
        "            df_ndvi = df_ndvi.iloc[:, :2].copy() # Pega só as duas primeiras colunas\n",
        "            df_ndvi.columns = ['Data', 'NDVI']\n",
        "            # Remove a linha que contém 'Data', 'NDVI' como valores\n",
        "            df_ndvi = df_ndvi[df_ndvi['Data'] != 'Data'].reset_index(drop=True)\n",
        "        else:\n",
        "            raise ValueError(\"CSV NDVI não tem colunas suficientes após carregar com header=2.\")\n",
        "\n",
        "        # Converter tipos\n",
        "        df_ndvi['Data'] = pd.to_datetime(df_ndvi['Data'], format='%d/%m/%Y', errors='coerce')\n",
        "        df_ndvi.dropna(subset=['Data'], inplace=True)\n",
        "        if df_ndvi['NDVI'].dtype == 'object':\n",
        "           df_ndvi['NDVI'] = df_ndvi['NDVI'].astype(str).str.replace(',', '.', regex=False)\n",
        "        df_ndvi['NDVI'] = pd.to_numeric(df_ndvi['NDVI'], errors='coerce')\n",
        "        df_ndvi.dropna(subset=['NDVI'], inplace=True)\n",
        "        df_ndvi['Ano'] = df_ndvi['Data'].dt.year\n",
        "        print(f\"Arquivo NDVI '{NDVI_CSV_PATH}' carregado e limpo.\")\n",
        "        print(\"Head df_ndvi:\")\n",
        "        print(df_ndvi.head())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro Crítico: Arquivo NDVI '{NDVI_CSV_PATH}' não encontrado.\")\n",
        "        df_ndvi = None # Garante que está None se falhar\n",
        "    except Exception as e:\n",
        "        print(f\"Erro Crítico ao processar NDVI: {e}\")\n",
        "        df_ndvi = None # Garante que está None se falhar\n",
        "else:\n",
        "    print(\"Carregamento de NDVI pulado pois o arquivo de produtividade não foi carregado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfz5LbW17vCX"
      },
      "source": [
        "Célula 10: Integração de Dados Tabulares e Engenharia de Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8DjuhaA7wyn"
      },
      "outputs": [],
      "source": [
        "# Verificar se ambos DataFrames foram carregados\n",
        "if df_prod is not None and df_ndvi is not None:\n",
        "    print(\"\\n--- Integrando Dados e Criando Features ---\")\n",
        "\n",
        "    # Agregar NDVI por Ano\n",
        "    max_prod_year = df_prod['Ano'].max()\n",
        "    df_ndvi_filtered = df_ndvi[df_ndvi['Ano'] <= max_prod_year].copy()\n",
        "    ndvi_threshold = 0.1 # Filtro para remover ruídos\n",
        "    df_ndvi_filtered_positive = df_ndvi_filtered[df_ndvi_filtered['NDVI'] > ndvi_threshold]\n",
        "\n",
        "    if not df_ndvi_filtered_positive.empty:\n",
        "        df_ndvi_agg = df_ndvi_filtered_positive.groupby('Ano')['NDVI'].agg(\n",
        "            ndvi_medio='mean', ndvi_max='max', ndvi_min='min', ndvi_std='std', ndvi_count='count'\n",
        "        ).reset_index()\n",
        "        df_ndvi_agg['ndvi_std'] = df_ndvi_agg['ndvi_std'].fillna(0) # Preenche std=0 se só 1 valor no ano\n",
        "        print(\"NDVI agregado por ano.\")\n",
        "        print(\"Head df_ndvi_agg:\")\n",
        "        print(df_ndvi_agg.head())\n",
        "\n",
        "        # Merge\n",
        "        df_final = pd.merge(df_prod, df_ndvi_agg, on='Ano', how='left')\n",
        "        print(\"\\nMerge entre produtividade e NDVI realizado.\")\n",
        "\n",
        "        # Adicionar Features Lagged\n",
        "        df_final['Rendimento_Medio_kg_ha_lag1'] = df_final['Rendimento_Medio_kg_ha'].shift(1)\n",
        "        df_final['Area_Colhida_ha_lag1'] = df_final['Area_Colhida_ha'].shift(1)\n",
        "        print(\"Features lagged adicionadas.\")\n",
        "\n",
        "        # Limpeza final (remover NaNs do merge e do lag)\n",
        "        df_final_cleaned = df_final.dropna().copy()\n",
        "        print(f\"\\nDataFrame final pronto com {df_final_cleaned.shape[0]} linhas.\")\n",
        "        if not df_final_cleaned.empty:\n",
        "             print(f\"Cobertura Anual: {df_final_cleaned['Ano'].min()}-{df_final_cleaned['Ano'].max()}\")\n",
        "             print(\"Head df_final_cleaned:\")\n",
        "             print(df_final_cleaned.head())\n",
        "             print(\"\\nInfo df_final_cleaned:\")\n",
        "             df_final_cleaned.info()\n",
        "        else:\n",
        "            print(\"DataFrame final está vazio após limpeza (verificar merge e lags).\")\n",
        "\n",
        "    else:\n",
        "        print(\"Não há dados de NDVI válidos (acima do threshold) para agregar. Impossível continuar.\")\n",
        "        df_final_cleaned = pd.DataFrame() # Cria dataframe vazio para evitar erros abaixo\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Integração pulada: DataFrames df_prod ou df_ndvi não disponíveis. ---\")\n",
        "    df_final_cleaned = pd.DataFrame() # Cria dataframe vazio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX4L-XWC7yv4"
      },
      "source": [
        "Célula 11: Preparar Dados para Modelo de Rendimento e Dividir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucpdfcq470jR"
      },
      "outputs": [],
      "source": [
        "# Verificar se df_final_cleaned existe e não está vazio\n",
        "if 'df_final_cleaned' in locals() and not df_final_cleaned.empty:\n",
        "    print(\"\\n--- Preparando Dados para Modelagem de Rendimento ---\")\n",
        "    # Definir Features (X) e Target (y)\n",
        "    target = 'Rendimento_Medio_kg_ha'\n",
        "    # Incluir todas as colunas exceto 'Ano' e o próprio target\n",
        "    features = [col for col in df_final_cleaned.columns if col != target and col != 'Ano']\n",
        "\n",
        "    # Garantir que o target e todas as features existem\n",
        "    if target in df_final_cleaned.columns and all(f in df_final_cleaned.columns for f in features):\n",
        "        X = df_final_cleaned[features]\n",
        "        y = df_final_cleaned[target]\n",
        "        print(f\"Features (X) selecionadas: {features}\")\n",
        "        print(f\"Target (y) selecionado: {target}\")\n",
        "        print(f\"Shape de X: {X.shape}, Shape de y: {y.shape}\")\n",
        "\n",
        "        # Divisão Temporal Treino/Teste Manual\n",
        "        split_index = len(X) - TEST_YEARS_SPLIT\n",
        "        if split_index > 0 and TEST_YEARS_SPLIT > 0 :\n",
        "            X_train, X_test = X[:split_index], X[split_index:]\n",
        "            y_train, y_test = y[:split_index], y[split_index:]\n",
        "            # Guardar os anos para visualização\n",
        "            anos_train = df_final_cleaned['Ano'][:split_index].tolist()\n",
        "            anos_test = df_final_cleaned['Ano'][split_index:].tolist()\n",
        "            print(f\"Divisão Temporal: Treino ({min(anos_train)}-{max(anos_train)}), Teste ({min(anos_test)}-{max(anos_test)})\")\n",
        "            print(f\"Tamanho Treino: {X_train.shape[0]}, Tamanho Teste: {X_test.shape[0]}\")\n",
        "        else:\n",
        "            print(f\"Erro: Dados insuficientes ({len(X)} linhas) para criar conjunto de teste com {TEST_YEARS_SPLIT} anos.\")\n",
        "            # Resetar X_train, X_test etc para evitar erros na próxima célula\n",
        "            X_train, X_test, y_train, y_test, anos_test = None, None, None, None, None\n",
        "    else:\n",
        "        print(\"Erro: Coluna target ou alguma coluna de feature não encontrada no DataFrame final.\")\n",
        "        X_train, X_test, y_train, y_test, anos_test = None, None, None, None, None\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Preparação para modelagem pulada: df_final_cleaned não disponível ou vazio. ---\")\n",
        "    X_train, X_test, y_train, y_test, anos_test = None, None, None, None, None # Garante que não existem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mPrpCfe74Ow"
      },
      "source": [
        "Célula 12: Treinar Modelo de Previsão de Rendimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bltiMlfj74mh"
      },
      "outputs": [],
      "source": [
        "# Verificar se os dados de treino existem\n",
        "if X_train is not None and y_train is not None:\n",
        "    print(\"\\n--- Treinando Modelo RandomForestRegressor para Rendimento ---\")\n",
        "    # Instanciar o modelo\n",
        "    rf_model_yield = RandomForestRegressor(n_estimators=N_ESTIMATORS_RF,\n",
        "                                         random_state=RANDOM_STATE,\n",
        "                                         n_jobs=-1) # Usa todos os cores disponíveis\n",
        "\n",
        "    # Treinar o modelo\n",
        "    rf_model_yield.fit(X_train, y_train)\n",
        "    print(\"Modelo de previsão de rendimento treinado com sucesso.\")\n",
        "else:\n",
        "    print(\"\\n--- Treinamento do modelo de rendimento pulado: Dados de treino não disponíveis. ---\")\n",
        "    rf_model_yield = None # Garante que modelo não existe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llznQB7Q77lv"
      },
      "source": [
        "Célula 13: Avaliar e Visualizar Modelo de Rendimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoZNKWwP78tZ"
      },
      "outputs": [],
      "source": [
        "# Verificar se o modelo foi treinado e se há dados de teste\n",
        "if rf_model_yield is not None and X_test is not None and y_test is not None:\n",
        "    print(\"\\n--- Avaliando Modelo de Previsão de Rendimento ---\")\n",
        "    y_pred_yield = rf_model_yield.predict(X_test)\n",
        "\n",
        "    # Calcular Métricas\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_yield))\n",
        "    mae = mean_absolute_error(y_test, y_pred_yield)\n",
        "    r2 = r2_score(y_test, y_pred_yield)\n",
        "\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE:  {mae:.4f}\")\n",
        "    print(f\"R²:   {r2:.4f}\")\n",
        "    print(\"\\nLembrete da Análise: O R² negativo indica desempenho ruim no teste.\")\n",
        "    print(\"O modelo atual não generaliza bem para os anos não vistos.\")\n",
        "    print(\"Considere as sugestões anteriores para melhoria ou documente as limitações.\")\n",
        "\n",
        "\n",
        "    # Visualizar Resultados (Previsto vs Real)\n",
        "    print(\"\\n--- Gerando Gráfico Previsto vs Real (Rendimento) ---\")\n",
        "    plt.figure(figsize=(12, 7)) # Aumentar tamanho\n",
        "    plt.plot(anos_test, y_test, label='Real', marker='o', linewidth=2, markersize=8)\n",
        "    plt.plot(anos_test, y_pred_yield, label='Previsto (RandomForest)', marker='x', linestyle='--', markersize=8)\n",
        "    plt.xlabel('Ano', fontsize=12)\n",
        "    plt.ylabel(f'{target} (kg/ha)', fontsize=12)\n",
        "    plt.title('Previsão de Rendimento Médio - Conjunto de Teste (Anos {})'.format(f\"{min(anos_test)}-{max(anos_test)}\"), fontsize=14)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.xticks(anos_test, rotation=45) # Mostrar todos os anos no eixo x do teste\n",
        "    plt.tight_layout() # Ajusta o layout para não cortar labels\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Avaliação/Visualização do modelo de rendimento pulada: Modelo ou dados de teste não disponíveis. ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MheM-zbw7_jH"
      },
      "source": [
        "Célula 14: Importância das Features (Modelo de Rendimento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cOR72xs8AwJ"
      },
      "outputs": [],
      "source": [
        "# Verificar se o modelo e as features existem\n",
        "if rf_model_yield is not None and 'features' in locals() and X_train is not None :\n",
        "    try:\n",
        "        print(\"\\n--- Importância das Features (Modelo de Rendimento) ---\")\n",
        "        importances = rf_model_yield.feature_importances_\n",
        "        # Criar dataframe de importância\n",
        "        feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "        print(feature_importance_df)\n",
        "\n",
        "        # Plotar importância\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis', hue='Feature', legend=False)\n",
        "        plt.title('Importância das Features - Modelo de Rendimento (RandomForest)', fontsize=14)\n",
        "        plt.xlabel('Importância Relativa', fontsize=12)\n",
        "        plt.ylabel('Feature', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível calcular/plotar a importância das features: {e}\")\n",
        "else:\n",
        "    print(\"\\n--- Cálculo da importância das features pulado: Modelo ou features não disponíveis. ---\")\n",
        "\n",
        "print(\"\\n--- Fim do Notebook ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
